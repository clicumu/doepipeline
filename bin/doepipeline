#!/usr/bin/env python
"""
Optimize a data-processing pipeline specified in config-file using
principles from statistical Design of Experiments (DoE).
"""
import argparse
import getpass
import os
import sys
import platform
from doepipeline.executor import SSHExecutor, LocalExecutor
from doepipeline.generator import PipelineGenerator


class Range:
    """
    Type checker-class for float input required to be within an interval.
    """
    def __init__(self, start, end):
        self.start = start
        self.end = end

    def __eq__(self, other):
        return self.start <= other <= self.end

    def __repr__(self):
        return '{0}-{1}'.format(self.start, self.end)


def make_parser():
    """ Create and config argument-parser.

    :return: prepared parser.
    :rtype: argparse.ArgumentParser
    """
    parser = argparse.ArgumentParser(
        description=__doc__, formatter_class=argparse.RawDescriptionHelpFormatter
    )
    parser.add_argument('config', help='pipeline config-file')
    parser.add_argument('-e', '--execution', default='serial',
                          help=('how to execute steps in pipeline '
                                '(default serial)'),
                          choices=('serial', 'slurm'))
    parser.add_argument('-w', '--workdir',
                        help='working directory (default: .)',
                        default='.')

    parser.add_argument('-i', '--maxiter', default=10, type=int,
                        choices=[Range(1, 100)],
                        help=('maximum number of iterations (default: 10)'))

    parser.add_argument('--tol', type=float, default=.25, choices=[Range(0, 1)],
                        help=('maximum allowed relative distance between '
                              'predicted optimum to edge of experimental '
                              'design in order to consider optimization '
                              'converged (default: 0.25)'))

    parser.add_argument('--degree', type=int, choices=[Range(1, 3)],
                        default=2, help='degree of polynomial fitted during '
                                        'optimization (default: 2)')
    parser.add_argument('-o', '--output', default='optimal_parameters.csv',
                        help='output file (default: optimal_parameters.csv)')

    # ---------------- Add sub-parsers.
    subparsers = parser.add_subparsers(title='program', dest='program',
                                       help='execution mode')
    subparsers.required = True
    subparsers.add_parser('local')

    # -------------- Connection arguments for remote parser
    remote_parser = subparsers.add_parser('remote')

    remote_parser.add_argument('user', help='user at HOST')
    remote_parser.add_argument('host', help='host to connect to.')
    remote_parser.add_argument('-k', '--key',
                               help=('public key file (key or path to key-file)'
                                     '. If provided SSH-authentication will be '
                                     'performed using provided key.'))
    remote_parser.add_argument('-p', '--password', action='store_true',
                               default=False,
                               help=('if this flag is set, the user will be '
                                     'prompted for password when connection '
                                     'with SSH to HOST.'))

    return parser


if __name__ == '__main__':
    parser = make_parser()
    args = parser.parse_args()

    if args.program == 'remote':
        host = args.host
        user = args.user

        auth = {
            'hostname': host,
            'username': user,
        }
        if args.password:
            prompt = "{0}@{1}'s password: ".format(user, host)
            auth['password'] = getpass.getpass(prompt)
        if args.key:
            if os.path.isfile(args.key):
                auth['key_filename'] = args.key
            else:
                auth['pkey'] = args.key

        executor_class = lambda *a, **kw: SSHExecutor(auth, *a, **kw)
        sep = '/'
    else:
        executor_class = LocalExecutor
        if platform.system() == 'Windows':
            sep = '\\'
        else:
            sep = '/'

    try:
        generator = PipelineGenerator.from_yaml(args.config)
    except ValueError as e:
        sys.exit(str(e))

    designer = generator.new_designer_from_config()

    n_iter = 0
    while n_iter < args.maxiter:
        n_iter += 1

        iter_workdir = sep.join((args.workdir, 'iter_'.format(n_iter)))
        executor = executor_class(
            execution_type=args.execution, workdir=iter_workdir,
            base_command='{script}')

        design = designer.new_design()
        pipeline = generator.new_pipeline_collection(design)
        results = executor.run_pipeline_collection(pipeline)
        optimum = designer.update_factors_from_response(results, tol=args.tol)

        if optimum.converged:
            optimum.predicted_optimum.to_csv(args.output)
            break

    if not optimum.converged:
        try:
            prefix, suffix = args.output.rsplit('.', 1)
        except ValueError:
            prefix = args.output
            suffix = ''

        outpath = '.'.join([prefix, 'unconverged', suffix])
        optimum.predicted_optimum.to_csv(outpath)